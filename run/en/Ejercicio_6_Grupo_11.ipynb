{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b3f26b",
   "metadata": {},
   "source": [
    "## 6. GDA\n",
    "Implementen su propia versión de un modelo GDA sobre el mismo dataset que el punto anterior y compare sus resultados. ¿Que modelo dió mejor accuracy? ¿Que similitudes o diferencias encuentran en los parámetros obtenidos? ¿Es posible sacar alguna conclusión de estos resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1dc0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src')\n",
    "\n",
    "from lda import LDA\n",
    "from gda import GDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eddfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDA:0.76\n",
      "LDA:0.89\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el dataset\n",
    "df = pd.read_csv(\"Datos/dataset.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "# Separar features y labels\n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"].map({\"'Male'\": 0, \"'Female'\": 1})  # Convertir a valores numéricos\n",
    "\n",
    "# Hago un resample para balancear las clases\n",
    "X_resampled, y_resampled = RandomOverSampler().fit_resample(X, y)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "GDA_Prueba = GDA()\n",
    "GDA_Prueba.fit(X_train,y_train)\n",
    "# Accuracy\n",
    "print('GDA:'+ str(np.mean(GDA_Prueba.predict(X_test) == y_test)))\n",
    "\n",
    "LDA_Prueba = LDA()\n",
    "LDA_Prueba.fit(X_train, y_train)\n",
    "# Accuracy\n",
    "print('LDA:'+ str(np.mean(LDA_Prueba.predict(X_test) == y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248da248",
   "metadata": {},
   "source": [
    "En todas las pruebas, las predicciones que realiza GDA son menos acertadas que las que devuele LDA. Esto puede deberse a que este último asume que las clases comparten la misma matriz de covarianza, lo que resulta en una frontera de decisión lineal. En este dataset, esa suposición parece ajustarse mejor a los datos, permitiendo que LDA generalice mejor y obtenga mayor accuracy. Por otro lado, GDA estima una matriz de covarianza diferente para cada clase, lo que puede llevar a sobreajuste si el número de muestras no es suficientemente grande o si las clases no son realmente tan diferentes en su dispersión. Además, los parámetros obtenidos por LDA suelen ser más estables y menos sensibles al ruido, mientras que GDA puede capturar mejor relaciones no lineales si existen, pero en este caso no aporta ventajas claras. En conclusión, la simplicidad de LDA lo hace más robusto para este problema en particular."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
